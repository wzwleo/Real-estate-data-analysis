# components/market_trend.py - å®Œæ•´åŠŸèƒ½ç‰ˆ
import streamlit as st
import pandas as pd
import os
import sys
import time
from streamlit_echarts import st_echarts
import google.generativeai as genai

# ä¿®æ­£åŒ¯å…¥è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

try:
    from config import PAGE_MODULES_FOLDER
    from analysis.gemini_analysis import prepare_market_analysis_prompt
    CONFIG_LOADED = True
except ImportError as e:
    CONFIG_LOADED = False
    st.warning(f"ç„¡æ³•è¼‰å…¥è¨­å®šæˆ–æ¨¡çµ„: {e}")


class MarketTrendAnalyzer:
    """å¸‚å ´è¶¨å‹¢åˆ†æå™¨ - å®Œæ•´åŠŸèƒ½ç‰ˆ"""
    
    def __init__(self):
        self.combined_df = None
        self.population_df = None
        
    def render_analysis_tab(self):
        """æ¸²æŸ“å¸‚å ´è¶¨å‹¢åˆ†æé é¢ - å®Œæ•´åŠŸèƒ½"""
        st.subheader("ğŸ“Š å¸‚å ´è¶¨å‹¢åˆ†æ")
        
        # åˆå§‹åŒ– session state
        if 'market_analysis_result' not in st.session_state:
            st.session_state.market_analysis_result = None
        if 'market_analysis_key' not in st.session_state:
            st.session_state.market_analysis_key = None
        
        # è¼‰å…¥è³‡æ–™
        self.combined_df = self._load_real_estate_data()
        self.population_df = self._load_population_data()
        
        if self.combined_df.empty or self.population_df.empty:
            st.info("ğŸ“‚ æ‰¾ä¸åˆ°æˆ¿ç”¢æˆ–äººå£è³‡æ–™")
            return
        
        # åŸºæœ¬æ¸…ç†
        self._clean_data()
        
        # äººå£è³‡æ–™è½‰é•·æ ¼å¼
        pop_long = self._prepare_population_data()
        
        # ç¯©é¸æ¢ä»¶
        city_choice, district_choice, year_range = self._render_filters(pop_long)
        
        # ç¯©é¸è³‡æ–™
        re_df, pop_df = self._filter_data(city_choice, district_choice, year_range, pop_long)
        
        # é¡¯ç¤ºè³‡æ–™è¡¨
        self._display_data_tables(re_df, pop_df, year_range)
        
        # é¸æ“‡åˆ†æé¡å‹
        chart_type = st.selectbox(
            "é¸æ“‡åˆ†æé¡å‹",
            [
                "ä¸å‹•ç”¢åƒ¹æ ¼è¶¨å‹¢åˆ†æï¼ˆå«äº¤æ˜“çµæ§‹ï¼‰",
                "äº¤æ˜“ç­†æ•¸åˆ†å¸ƒï¼ˆçµæ§‹ï¼‰",
                "äººå£ Ã— æˆäº¤é‡ï¼ˆå¸‚å ´æ˜¯å¦è¢«å£“æŠ‘ï¼‰"
            ],
            key="market_chart_type"
        )
        
        # åŸ·è¡Œåˆ†æ
        if chart_type:
            analysis_data = self._perform_chart_analysis(
                chart_type, re_df, pop_df, city_choice, district_choice, year_range
            )
            
            # AI åˆ†æ
            if analysis_data:
                self._render_ai_analysis(
                    chart_type,
                    analysis_data,
                    re_df,
                    pop_df,
                    city_choice,
                    district_choice,
                    year_range
                )
    
    def _load_real_estate_data(self):
        """è¼‰å…¥ä¸å‹•ç”¢è³‡æ–™"""
        try:
            data_dir = PAGE_MODULES_FOLDER
            csv_files = [f for f in os.listdir(data_dir) 
                        if f.startswith("åˆä½µå¾Œä¸å‹•ç”¢çµ±è¨ˆ_") and f.endswith(".csv")]
            
            if not csv_files:
                st.warning("æ‰¾ä¸åˆ°ä¸å‹•ç”¢è³‡æ–™æª”æ¡ˆ")
                return pd.DataFrame()
            
            dfs = []
            for file in csv_files:
                file_path = os.path.join(data_dir, file)
                try:
                    df = pd.read_csv(file_path, encoding="utf-8")
                except:
                    try:
                        df = pd.read_csv(file_path, encoding="big5")
                    except:
                        continue
                dfs.append(df)
            
            if dfs:
                return pd.concat(dfs, ignore_index=True)
            else:
                return pd.DataFrame()
                
        except Exception as e:
            st.error(f"è¼‰å…¥ä¸å‹•ç”¢è³‡æ–™å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def _load_population_data(self):
        """è¼‰å…¥äººå£è³‡æ–™"""
        try:
            data_dir = PAGE_MODULES_FOLDER
            file_path = os.path.join(data_dir, "NEWWWW.csv")
            
            if not os.path.exists(file_path):
                st.warning(f"æ‰¾ä¸åˆ°äººå£è³‡æ–™æª”æ¡ˆ: {file_path}")
                return pd.DataFrame()
            
            try:
                df = pd.read_csv(file_path, encoding="utf-8")
            except:
                df = pd.read_csv(file_path, encoding="big5")
            
            return df
            
        except Exception as e:
            st.error(f"è¼‰å…¥äººå£è³‡æ–™å¤±æ•—: {e}")
            return pd.DataFrame()
    
    def _clean_data(self):
        """æ¸…ç†è³‡æ–™"""
        if "å­£åº¦" in self.combined_df.columns:
            self.combined_df["æ°‘åœ‹å¹´"] = self.combined_df["å­£åº¦"].str[:3].astype(int)
        
        # æ¸…ç†äººå£è³‡æ–™æ¬„ä½åç¨±
        self.population_df.columns = [str(c).strip().replace("ã€€", "") for c in self.population_df.columns]
        self.population_df["ç¸£å¸‚"] = self.population_df["ç¸£å¸‚"].astype(str).str.strip()
        self.population_df["è¡Œæ”¿å€"] = self.population_df["è¡Œæ”¿å€"].astype(str).str.strip()
    
    def _prepare_population_data(self):
        """æº–å‚™äººå£è³‡æ–™ï¼ˆè½‰é•·æ ¼å¼ï¼‰"""
        year_cols = [c for c in self.population_df.columns if "å¹´" in c]
        pop_long = self.population_df.melt(
            id_vars=["ç¸£å¸‚", "è¡Œæ”¿å€"],
            value_vars=year_cols,
            var_name="å¹´åº¦",
            value_name="äººå£æ•¸"
        )
        
        pop_long["äººå£æ•¸"] = (
            pop_long["äººå£æ•¸"].astype(str).str.replace(",", "").astype(int)
        )
        pop_long["æ°‘åœ‹å¹´"] = pop_long["å¹´åº¦"].str[:3].astype(int)
        
        return pop_long
    
    def _render_filters(self, pop_long):
        """æ¸²æŸ“ç¯©é¸æ¢ä»¶"""
        col_main, col_filter = st.columns([3, 1])
        
        with col_filter:
            cities = ["å…¨å°"] + sorted(self.combined_df["ç¸£å¸‚"].unique())
            city_choice = st.selectbox("é¸æ“‡ç¸£å¸‚", cities, key="city_choice")
            
            if city_choice != "å…¨å°":
                district_choice = st.selectbox(
                    "é¸æ“‡è¡Œæ”¿å€",
                    ["å…¨éƒ¨"] + sorted(
                        self.combined_df[self.combined_df["ç¸£å¸‚"] == city_choice]["è¡Œæ”¿å€"].unique()
                    ),
                    key="district_choice"
                )
            else:
                district_choice = "å…¨éƒ¨"
            
            year_min = int(min(self.combined_df["æ°‘åœ‹å¹´"].min(), pop_long["æ°‘åœ‹å¹´"].min()))
            year_max = int(max(self.combined_df["æ°‘åœ‹å¹´"].max(), pop_long["æ°‘åœ‹å¹´"].max()))
            
            year_range = st.slider(
                "é¸æ“‡åˆ†æå¹´ä»½",
                min_value=year_min,
                max_value=year_max,
                value=(year_min, year_max),
                key="year_range"
            )
        
        return city_choice, district_choice, year_range
    
    def _filter_data(self, city_choice, district_choice, year_range, pop_long):
        """ç¯©é¸è³‡æ–™"""
        # ä¸å‹•ç”¢è³‡æ–™ç¯©é¸
        re_df = self.combined_df[
            (self.combined_df["æ°‘åœ‹å¹´"] >= year_range[0]) &
            (self.combined_df["æ°‘åœ‹å¹´"] <= year_range[1])
        ]
        
        if city_choice != "å…¨å°":
            re_df = re_df[re_df["ç¸£å¸‚"] == city_choice]
            if district_choice != "å…¨éƒ¨":
                re_df = re_df[re_df["è¡Œæ”¿å€"] == district_choice]
        
        # äººå£è³‡æ–™ç¯©é¸
        pop_df = pop_long[
            (pop_long["æ°‘åœ‹å¹´"] >= year_range[0]) &
            (pop_long["æ°‘åœ‹å¹´"] <= year_range[1])
        ]
        
        if city_choice == "å…¨å°":
            pop_df = pop_df[pop_df["ç¸£å¸‚"] == pop_df["è¡Œæ”¿å€"]]
        elif district_choice == "å…¨éƒ¨":
            pop_df = pop_df[
                (pop_df["ç¸£å¸‚"] == city_choice) &
                (pop_df["è¡Œæ”¿å€"] == city_choice)
            ]
        else:
            pop_df = pop_df[
                (pop_df["ç¸£å¸‚"] == city_choice) &
                (pop_df["è¡Œæ”¿å€"] == district_choice)
            ]
        
        return re_df, pop_df
    
    def _display_data_tables(self, re_df, pop_df, year_range):
        """é¡¯ç¤ºè³‡æ–™è¡¨"""
        col_main, _ = st.columns([3, 1])
        
        with col_main:
            # è¡¨æ ¼ 1ï¼šä¸å‹•ç”¢è³‡æ–™
            with st.expander("ğŸ“‚ è¡¨ä¸€ï¼šä¸å‹•ç”¢è³‡æ–™ï¼ˆé»æ“Šå±•é–‹ï¼‰", expanded=True):
                if not re_df.empty:
                    st.dataframe(re_df, use_container_width=True)
                    st.caption(f"å…± {len(re_df)} ç­†ä¸å‹•ç”¢äº¤æ˜“è¨˜éŒ„")
                else:
                    st.warning("è©²æ¢ä»¶ä¸‹ç„¡ä¸å‹•ç”¢è³‡æ–™")
            
            # è¡¨æ ¼ 2ï¼šäººå£è³‡æ–™
            with st.expander("ğŸ‘¥ è¡¨äºŒï¼šäººå£è³‡æ–™ï¼ˆå¹´åº¦ï¼Œé»æ“Šå±•é–‹ï¼‰", expanded=False):
                if not pop_df.empty:
                    pivot_df = pop_df.pivot_table(
                        index=["ç¸£å¸‚", "è¡Œæ”¿å€"],
                        columns="æ°‘åœ‹å¹´",
                        values="äººå£æ•¸",
                        aggfunc="last"
                    ).fillna(0).astype(int)
                    
                    st.dataframe(pivot_df, use_container_width=True)
                    st.caption(f"äººå£è³‡æ–™ç¯„åœï¼š{year_range[0]} - {year_range[1]} å¹´")
                else:
                    st.warning("è©²æ¢ä»¶ä¸‹ç„¡äººå£è³‡æ–™")
    
    def _perform_chart_analysis(self, chart_type, re_df, pop_df, city_choice, district_choice, year_range):
        """åŸ·è¡Œåœ–è¡¨åˆ†æ"""
        analysis_data = {}
        
        if chart_type == "ä¸å‹•ç”¢åƒ¹æ ¼è¶¨å‹¢åˆ†æï¼ˆå«äº¤æ˜“çµæ§‹ï¼‰":
            analysis_data = self._analyze_price_trend(re_df, city_choice, district_choice, year_range)
        
        elif chart_type == "äº¤æ˜“ç­†æ•¸åˆ†å¸ƒï¼ˆçµæ§‹ï¼‰":
            analysis_data = self._analyze_transaction_distribution(re_df, city_choice, district_choice, year_range)
        
        elif chart_type == "äººå£ Ã— æˆäº¤é‡ï¼ˆå¸‚å ´æ˜¯å¦è¢«å£“æŠ‘ï¼‰":
            analysis_data = self._analyze_population_vs_transactions(re_df, pop_df, city_choice, district_choice, year_range)
        
        return analysis_data
    
    def _analyze_price_trend(self, re_df, city_choice, district_choice, year_range):
        """åˆ†æåƒ¹æ ¼è¶¨å‹¢"""
        # åƒ¹æ ¼è¶¨å‹¢
        price_df = re_df.groupby(["æ°‘åœ‹å¹´", "BUILD"])["å¹³å‡å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º"].mean().reset_index()
        years = sorted(price_df["æ°‘åœ‹å¹´"].unique())
        
        def safe_mean_price(year, build):
            s = price_df[(price_df["æ°‘åœ‹å¹´"] == year) & (price_df["BUILD"] == build)]["å¹³å‡å–®åƒ¹å…ƒå¹³æ–¹å…¬å°º"]
            return int(s.mean()) if not s.empty else 0
        
        new_price = [safe_mean_price(y, "æ–°æˆå±‹") for y in years]
        old_price = [safe_mean_price(y, "ä¸­å¤å±‹") for y in years]
        
        # é¡¯ç¤ºåœ–è¡¨
        st.markdown("### ğŸ“ˆ åƒ¹æ ¼è¶¨å‹¢ï¼ˆæ–°æˆå±‹ vs ä¸­å¤å±‹ï¼‰")
        st_echarts({
            "tooltip": {"trigger": "axis"},
            "legend": {"data": ["æ–°æˆå±‹", "ä¸­å¤å±‹"]},
            "xAxis": {"type": "category", "data": [str(y) for y in years]},
            "yAxis": {"type": "value"},
            "series": [
                {"name": "æ–°æˆå±‹", "type": "line", "data": new_price},
                {"name": "ä¸­å¤å±‹", "type": "line", "data": old_price}
            ]
        }, height="350px")
        
        # äº¤æ˜“çµæ§‹
        trans_df = re_df.groupby(["æ°‘åœ‹å¹´", "BUILD"])["äº¤æ˜“ç­†æ•¸"].sum().reset_index()
        
        def safe_sum_trans(year, build):
            s = trans_df[(trans_df["æ°‘åœ‹å¹´"] == year) & (trans_df["BUILD"] == build)]["äº¤æ˜“ç­†æ•¸"]
            return int(s.sum()) if not s.empty else 0
        
        new_trans = [safe_sum_trans(y, "æ–°æˆå±‹") for y in years]
        old_trans = [safe_sum_trans(y, "ä¸­å¤å±‹") for y in years]
        
        st.markdown("### ğŸ“Š äº¤æ˜“çµæ§‹ï¼ˆé‡çš„ä¾†æºï¼‰")
        st_echarts({
            "tooltip": {"trigger": "axis"},
            "legend": {"data": ["æ–°æˆå±‹", "ä¸­å¤å±‹"]},
            "xAxis": {"type": "category", "data": [str(y) for y in years]},
            "yAxis": {"type": "value"},
            "series": [
                {"name": "æ–°æˆå±‹", "type": "bar", "stack": "total", "data": new_trans},
                {"name": "ä¸­å¤å±‹", "type": "bar", "stack": "total", "data": old_trans}
            ]
        }, height="350px")
        
        return {
            "years": years,
            "new_price": new_price,
            "old_price": old_price,
            "new_trans": new_trans,
            "old_trans": old_trans,
            "city": city_choice,
            "district": district_choice,
            "year_range": year_range,
            "chart_type": "åƒ¹æ ¼è¶¨å‹¢èˆ‡äº¤æ˜“çµæ§‹",
            "total_transactions": sum(new_trans) + sum(old_trans)
        }
    
    def _analyze_transaction_distribution(self, re_df, city_choice, district_choice, year_range):
        """åˆ†æäº¤æ˜“ç­†æ•¸åˆ†å¸ƒ"""
        # è¡Œæ”¿å€äº¤æ˜“é‡æ’è¡Œ
        total_trans = re_df.groupby("è¡Œæ”¿å€")["äº¤æ˜“ç­†æ•¸"].sum().reset_index()
        total_trans = total_trans.sort_values("äº¤æ˜“ç­†æ•¸", ascending=True).tail(10)
        
        st.markdown("### ğŸ“Š è¡Œæ”¿å€äº¤æ˜“é‡æ’è¡Œï¼ˆTop 10ï¼‰")
        st_echarts({
            "tooltip": {"trigger": "axis"},
            "xAxis": {"type": "value"},
            "yAxis": {"type": "category", "data": total_trans["è¡Œæ”¿å€"].tolist()},
            "series": [{"type": "bar", "data": total_trans["äº¤æ˜“ç­†æ•¸"].astype(int).tolist()}]
        }, height="400px")
        
        # æ¯å¹´äº¤æ˜“ç­†æ•¸ Top 3
        yearly_top3_data = {}
        years = sorted(re_df["æ°‘åœ‹å¹´"].unique())
        
        for y in years:
            df_y = re_df[re_df["æ°‘åœ‹å¹´"] == y]
            top3 = df_y.groupby("è¡Œæ”¿å€")["äº¤æ˜“ç­†æ•¸"].sum().reset_index()
            top3 = top3.sort_values("äº¤æ˜“ç­†æ•¸", ascending=False).head(3)
            yearly_top3_data[y] = top3
        
        return {
            "top_districts": total_trans.to_dict('records'),
            "yearly_top3": yearly_top3_data,
            "city": city_choice,
            "district": district_choice,
            "year_range": year_range,
            "chart_type": "äº¤æ˜“ç­†æ•¸åˆ†å¸ƒ",
            "total_years": len(years)
        }
    
    def _analyze_population_vs_transactions(self, re_df, pop_df, city_choice, district_choice, year_range):
        """åˆ†æäººå£èˆ‡æˆäº¤é‡é—œä¿‚"""
        pop_year = pop_df.groupby("æ°‘åœ‹å¹´")["äººå£æ•¸"].last().reset_index()
        trans_year = re_df.groupby("æ°‘åœ‹å¹´")["äº¤æ˜“ç­†æ•¸"].sum().reset_index()
        
        merged = pd.merge(pop_year, trans_year, on="æ°‘åœ‹å¹´", how="left").fillna(0)
        
        st.markdown("### ğŸ“Š äººå£èˆ‡æˆäº¤é‡è¶¨å‹¢å°æ¯”")
        st_echarts({
            "tooltip": {"trigger": "axis"},
            "legend": {"data": ["äººå£æ•¸", "æˆäº¤é‡"]},
            "xAxis": {"type": "category", "data": merged["æ°‘åœ‹å¹´"].astype(str).tolist()},
            "yAxis": [{"type": "value"}, {"type": "value"}],
            "series": [
                {"name": "äººå£æ•¸", "type": "line", "data": merged["äººå£æ•¸"].tolist()},
                {"name": "æˆäº¤é‡", "type": "line", "yAxisIndex": 1, "data": merged["äº¤æ˜“ç­†æ•¸"].tolist()}
            ]
        }, height="400px")
        
        # è¨ˆç®—å¸‚å ´å£“æŠ‘æŒ‡æ•¸
        pop_change, trans_change, suppression_index = self._calculate_suppression_index(merged)
        
        return {
            "population_trend": merged.to_dict('records'),
            "city": city_choice,
            "district": district_choice,
            "year_range": year_range,
            "chart_type": "äººå£èˆ‡æˆäº¤é‡é—œä¿‚",
            "pop_change": pop_change,
            "trans_change": trans_change,
            "suppression_index": suppression_index
        }
    
    def _calculate_suppression_index(self, merged_df):
        """è¨ˆç®—å¸‚å ´å£“æŠ‘æŒ‡æ•¸"""
        if len(merged_df) <= 1:
            return 0, 0, 0
        
        pop_change = ((merged_df["äººå£æ•¸"].iloc[-1] - merged_df["äººå£æ•¸"].iloc[0]) / merged_df["äººå£æ•¸"].iloc[0]) * 100
        trans_change = ((merged_df["äº¤æ˜“ç­†æ•¸"].iloc[-1] - merged_df["äº¤æ˜“ç­†æ•¸"].iloc[0]) / merged_df["äº¤æ˜“ç­†æ•¸"].iloc[0]) * 100
        
        suppression_index = pop_change - trans_change if pop_change > 0 else 0
        
        return pop_change, trans_change, suppression_index
    
    def _render_ai_analysis(self, chart_type, analysis_data, re_df, pop_df, city_choice, district_choice, year_range):
        """æ¸²æŸ“ AI åˆ†æ"""
        st.markdown("---")
        st.subheader("ğŸ¤– AI å¸‚å ´è¶¨å‹¢åˆ†æ")
        
        # å»ºç«‹åˆ†æéµå€¼
        analysis_params_key = f"{chart_type}_{city_choice}_{district_choice}_{year_range[0]}_{year_range[1]}"
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ†æ
        should_reanalyze = (
            st.session_state.get("market_analysis_key") != analysis_params_key or
            st.session_state.market_analysis_result is None
        )
        
        gemini_key = st.session_state.get("GEMINI_KEY", "")
        
        if gemini_key:
            col1, col2, col3 = st.columns([1, 2, 2])
            
            with col1:
                if st.button("ğŸš€ å•Ÿå‹• AI åˆ†æ", type="primary", use_container_width=True, key="start_market_analysis"):
                    self._call_gemini_analysis(chart_type, analysis_data, re_df, pop_df, analysis_params_key, gemini_key)
            
            with col2:
                if st.session_state.get("market_analysis_key") == analysis_params_key:
                    st.success("âœ… å·²æœ‰åˆ†æçµæœ")
                elif should_reanalyze:
                    st.info("ğŸ”„ éœ€è¦é‡æ–°åˆ†æ")
                else:
                    st.info("ğŸ‘† é»æ“ŠæŒ‰éˆ•é–‹å§‹åˆ†æ")
                    
            with col3:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤åˆ†æçµæœ", type="secondary", use_container_width=True, key="clear_analysis"):
                    st.session_state.market_analysis_result = None
                    st.session_state.market_analysis_key = None
                    st.rerun()
        else:
            st.warning("è«‹åœ¨å´é‚Šæ¬„å¡«å…¥ Gemini API é‡‘é‘°ä»¥ä½¿ç”¨ AI åˆ†æåŠŸèƒ½")
        
        # é¡¯ç¤ºåˆ†æçµæœ
        if st.session_state.market_analysis_result and st.session_state.market_analysis_key == analysis_params_key:
            st.markdown("### ğŸ“Š AI åˆ†æå ±å‘Š")
            with st.container():
                st.markdown("---")
                st.markdown(st.session_state.market_analysis_result)
                st.markdown("---")
    
    def _call_gemini_analysis(self, chart_type, analysis_data, re_df, pop_df, analysis_key, gemini_key):
        """å‘¼å« Gemini åˆ†æ"""
        # é˜²çˆ†æª¢æŸ¥
        now = time.time()
        last = st.session_state.get("last_market_gemini_call", 0)
        
        if now - last < 30:
            st.warning("âš ï¸ Gemini åˆ†æè«‹ç­‰å¾… 30 ç§’å¾Œå†è©¦")
            return
        
        st.session_state.last_market_gemini_call = now
        
        # æº–å‚™æç¤ºè©
        prompt = self._prepare_market_analysis_prompt(chart_type, analysis_data, re_df, pop_df)
        
        # å‘¼å« Gemini
        with st.spinner("ğŸ§  AI åˆ†æå¸‚å ´è¶¨å‹¢ä¸­..."):
            try:
                genai.configure(api_key=gemini_key)
                model = genai.GenerativeModel("gemini-2.0-flash")
                
                resp = model.generate_content(prompt)
                
                # å„²å­˜çµæœ
                st.session_state.market_analysis_result = resp.text
                st.session_state.market_analysis_key = analysis_key
                
                st.success("âœ… AI åˆ†æå®Œæˆï¼")
                
            except Exception as e:
                st.error(f"âŒ Gemini API éŒ¯èª¤: {str(e)}")
    
    def _prepare_market_analysis_prompt(self, chart_type, analysis_data, re_df, pop_df):
        """æº–å‚™å¸‚å ´åˆ†ææç¤ºè©"""
        base_context = f"""
        ä½ æ˜¯ä¸€ä½è³‡æ·±ä¸å‹•ç”¢åˆ†æå¸«ï¼Œæ“æœ‰10å¹´å¸‚å ´åˆ†æç¶“é©—ã€‚
        è«‹é‡å°ä»¥ä¸‹æ•¸æ“šæä¾›å°ˆæ¥­ã€å®¢è§€çš„åˆ†æå ±å‘Šã€‚
        
        åˆ†æç¯„åœï¼š
        - åœ°å€ï¼š{analysis_data.get('city', 'å…¨å°')} - {analysis_data.get('district', 'å…¨éƒ¨')}
        - æ™‚é–“ï¼š{analysis_data.get('year_range', ())} å¹´
        - æ•¸æ“šé¡å‹ï¼š{chart_type}
        """
        
        if chart_type == "ä¸å‹•ç”¢åƒ¹æ ¼è¶¨å‹¢åˆ†æï¼ˆå«äº¤æ˜“çµæ§‹ï¼‰":
            return base_context + f"""
            
            å…·é«”æ•¸æ“šï¼š
            1. åƒ¹æ ¼è¶¨å‹¢ï¼š
               - åˆ†ææœŸé–“ï¼š{analysis_data.get('years', [])} å¹´
               - æ–°æˆå±‹åƒ¹æ ¼è¶¨å‹¢ï¼š{analysis_data.get('new_price', [])}
               - ä¸­å¤å±‹åƒ¹æ ¼è¶¨å‹¢ï¼š{analysis_data.get('old_price', [])}
            
            2. äº¤æ˜“çµæ§‹ï¼š
               - æ–°æˆå±‹äº¤æ˜“é‡ï¼š{analysis_data.get('new_trans', [])}
               - ä¸­å¤å±‹äº¤æ˜“é‡ï¼š{analysis_data.get('old_trans', [])}
            
            è«‹æä¾›å°ˆæ¥­çš„å¸‚å ´åˆ†æå ±å‘Šã€‚
            """
        
        elif chart_type == "äº¤æ˜“ç­†æ•¸åˆ†å¸ƒï¼ˆçµæ§‹ï¼‰":
            return base_context + f"""
            
            å…·é«”æ•¸æ“šï¼š
            1. äº¤æ˜“é‡Top 10è¡Œæ”¿å€ï¼š{analysis_data.get('top_districts', [])}
            
            è«‹æä¾›å°ˆæ¥­çš„å€åŸŸç†±åº¦åˆ†æå ±å‘Šã€‚
            """
        
        elif chart_type == "äººå£ Ã— æˆäº¤é‡ï¼ˆå¸‚å ´æ˜¯å¦è¢«å£“æŠ‘ï¼‰":
            return base_context + f"""
            
            å…·é«”æ•¸æ“šï¼š
            äººå£èˆ‡æˆäº¤é‡è¶¨å‹¢ï¼š{analysis_data.get('population_trend', [])}
            
            è«‹æä¾›å°ˆæ¥­çš„äººå£èˆ‡å¸‚å ´é—œä¿‚åˆ†æå ±å‘Šã€‚
            """
        
        return base_context
