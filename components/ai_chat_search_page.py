import streamlit as st
import google.generativeai as genai

def render_ai_chat_search():
    st.header("ğŸ¤– AI æˆ¿å¸‚é¡§å•")
    st.write("ä½ å¯ä»¥è¼¸å…¥è‡ªç„¶èªè¨€æŸ¥è©¢æ¢ä»¶ï¼ŒAI æœƒå¹«ä½ æœå°‹é©åˆçš„ç‰©ä»¶ã€‚")
    
    # ====== GEMINI_KEY é©—è­‰ ======
    gemini_key = st.session_state.get("GEMINI_KEY", "")
    if not gemini_key:
        st.error("âŒ å³å´ gemini API Key æœªè¨­å®šæˆ–æœ‰èª¤")
        st.stop()
    
    # ====== åˆå§‹åŒ– Gemini API ======
    try:
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
    except Exception as e:
        st.error(f"âŒ Gemini åˆå§‹åŒ–éŒ¯èª¤ï¼š{e}")
        st.stop()
    
    # ====== èŠå¤©è¨˜éŒ„åˆå§‹åŒ– ======
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # ====== ä½¿ç”¨è€…è¼¸å…¥ï¼ˆå…ˆè™•ç†è¼¸å…¥ï¼‰ ======
    if prompt := st.chat_input("è«‹è¼¸å…¥æŸ¥è©¢æ¢ä»¶ï¼Œä¾‹å¦‚ï¼šã€å°åŒ— 2000 è¬å…§ 3 æˆ¿ã€"):
        # åŠ å…¥ä½¿ç”¨è€…è¨Šæ¯åˆ°æ­·å²è¨˜éŒ„
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        try:
            # å‘¼å« Gemini AI
            response = model.generate_content(prompt)
            ai_reply = response.text
        except Exception as e:
            ai_reply = f"âŒ API ç™¼ç”ŸéŒ¯èª¤: {e}"
        
        # åŠ å…¥ AI å›æ‡‰åˆ°æ­·å²è¨˜éŒ„
        st.session_state.chat_history.append({"role": "assistant", "content": ai_reply})
    
    # ====== é¡¯ç¤ºèŠå¤©è¨˜éŒ„ï¼ˆåœ¨è¼¸å…¥æ¡†ä¸Šæ–¹ï¼‰ ======
    for chat in st.session_state.chat_history:
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"])
