import streamlit as st
import google.generativeai as genai

def render_ai_chat_search():
    st.header("ğŸ¤– AI æˆ¿å¸‚é¡§å•")
    st.write("ä½ å¯ä»¥è¼¸å…¥è‡ªç„¶èªè¨€æŸ¥è©¢æ¢ä»¶ï¼ŒAI æœƒå¹«ä½ æœå°‹é©åˆçš„ç‰©ä»¶ã€‚")
    
    # ====== GEMINI_KEY é©—è­‰ ======
    gemini_key = st.session_state.get("GEMINI_KEY", "")
    if not gemini_key:
        st.error("âŒ å³å´ gemini API Key æœªè¨­å®šæˆ–æœ‰èª¤")
        st.stop()
    
    # ====== åˆå§‹åŒ– Gemini API ======
    try:
        genai.configure(api_key=gemini_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
    except Exception as e:
        st.error(f"âŒ Gemini åˆå§‹åŒ–éŒ¯èª¤ï¼š{e}")
        st.stop()
    
    # ====== èŠå¤©è¨˜éŒ„åˆå§‹åŒ– ======
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # ====== é¡¯ç¤ºç¾æœ‰çš„èŠå¤©è¨˜éŒ„ ======
    for chat in st.session_state.chat_history:
        with st.chat_message(chat["role"]):
            st.markdown(chat["content"])
    
    # ====== ä½¿ç”¨è€…è¼¸å…¥ï¼ˆå›ºå®šåœ¨åº•éƒ¨ï¼‰ ======
    if prompt := st.chat_input("è«‹è¼¸å…¥æŸ¥è©¢æ¢ä»¶ï¼Œä¾‹å¦‚ï¼šã€å°åŒ— 2000 è¬å…§ 3 æˆ¿ã€"):
        # ç«‹å³é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        # å‘¼å« AI ä¸¦é¡¯ç¤ºå›æ‡‰
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                try:
                    response = model.generate_content(prompt)
                    ai_reply = response.text
                except Exception as e:
                    ai_reply = f"âŒ API ç™¼ç”ŸéŒ¯èª¤: {e}"
            
            st.markdown(ai_reply)
        
        st.session_state.chat_history.append({"role": "assistant", "content": ai_reply})
        st.rerun()  # é‡æ–°æ•´ç†ç•«é¢
